{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 456.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "text_loader_kwargs = {\"autodetect_encoding\": True}\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"./articles\",\n",
    "    glob=\"*.txt\",\n",
    "    show_progress=True,\n",
    "    use_multithreading=True,\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs=text_loader_kwargs\n",
    ")\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "embeddings = CohereEmbeddings(model=\"embed-multilingual-v3.0\", cohere_api_key =\"iF6RFJiNfggDlFuIKvRh12Po5oTfjqXdvvOxflvU\",user_agent=\"my-app\")\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents=data,\n",
    "    embedding=embeddings\n",
    "    ,persist_directory=\"./chroma_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.schema.messages import HumanMessage, AIMessage\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "llm = ChatCohere(cohere_api_key=\"iF6RFJiNfggDlFuIKvRh12Po5oTfjqXdvvOxflvU\", model=\"command-r-plus-08-2024\")\n",
    "embeddings = CohereEmbeddings(model=\"embed-multilingual-v3.0\", cohere_api_key =\"iF6RFJiNfggDlFuIKvRh12Po5oTfjqXdvvOxflvU\",user_agent=\"my-app\") \n",
    "retriever = Chroma(persist_directory=\"./chroma_db\", embedding_function=embeddings).as_retriever(search_kwargs={\"k\": 20})\n",
    "reranker = CohereRerank(cohere_api_key=\"iF6RFJiNfggDlFuIKvRh12Po5oTfjqXdvvOxflvU\", model=\"rerank-multilingual-v3.0\")\n",
    "\n",
    "system_prompt: str = (\n",
    "        \"Bạn là trợ lý trả lời văn bản luật tiếng Việt. \"\n",
    "        \"Sử dụng ngữ cảnh được cung cấp để trả lời câu hỏi. \"\n",
    "        \"\\n\\n\"\n",
    "        \"Ngữ cảnh: \\\"{context}\\\" \"\n",
    "        \"Bạn phải luôn trả lời từ nội dung, có thể cần phải dùng nhiều điều cho một lần trả lời, trích dẫn bắt buộc chính xác từng chữ. \"\n",
    "        \"Nếu trả lời bên ngoài ngữ cảnh phải đề cập là bên ngoài ngữ cảnh\"\n",
    "        # \"Nếu bạn không tìm thấy nội dung được hỏi từ ngữ cảnh, \"\n",
    "        # \"nói \\\"Tôi không biết\\\". Không được nói điều nào về \\\"ngữ cảnh được cung cấp\\\" trong câu trả lời.\"\n",
    ")\n",
    "contextualize_q_system_prompt = (\n",
    "        \"Với lịch sử hội thoại và câu hỏi mới nhất của người dùng có thể đề cập đến \"\n",
    "        \"ngữ cảnh trong lịch sử trò chuyện, hãy tổng hợp lại thành 1 câi hỏi độc lập \"\n",
    "        \"mà không cần phải biết lịch sử hội thoại để hiểu được. Bạn không được trả lời câu hỏi. \"\n",
    "        \"Chỉ cần tổng hợp lại thành 1 câu hỏi không cần lịch sử trò chuyện nếu cần, \"\n",
    "        \"còn không thì trả về câu hỏi gốc.\"\n",
    ")\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", contextualize_q_system_prompt),\n",
    "            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    ")\n",
    "prompt: ChatPromptTemplate = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "#            MessagesPlaceholder(\"chat_history\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    ")\n",
    "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=reranker,\n",
    "    base_retriever=retriever\n",
    ")\n",
    "\n",
    "rag_chain = create_retrieval_chain(compression_retriever, qa_chain)\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")\n",
    "def invoke_rag_with_history(user_query: str, session_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Invokes RAG chain and updates chat history\n",
    "    \"\"\"\n",
    "    # Get response from chain\n",
    "    response = conversational_rag_chain.invoke(\n",
    "        {\"input\": user_query},\n",
    "        {\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "    \n",
    "    # Update chat history\n",
    "    history = get_session_history(session_id)\n",
    "    history.add_user_message(HumanMessage(content=user_query))\n",
    "    history.add_ai_message(AIMessage(content=response[\"answer\"]))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xin lỗi, tôi không tìm thấy tên của bạn trong ngữ cảnh được cung cấp. Bạn có thể cho tôi biết tên của bạn là gì không?\n"
     ]
    }
   ],
   "source": [
    "# session_id = \"1\"\n",
    "# user_query =  \"Tôi vừa hỏi gì\"\n",
    "# response = conversational_rag_chain.invoke({\"input\": user_query},{'configurable': {'session_id': session_id}})\n",
    "response = invoke_rag_with_history(\"Tôi tên gì\", \"1\")\n",
    "print(response[\"answer\"])\n",
    "# store[session_id].add_user_message(HumanMessage(content=user_query))\n",
    "# store[session_id].add_ai_message(AIMessage(content=response[\"answer\"]))\n",
    "# compressed_docs = compression_retriever.get_relevant_documents(user_query)\n",
    "# print(compressed_docs)\n",
    "\n",
    "# # Create the cohere rag retriever using the chat model\n",
    "# rag = CohereRagRetriever(llm=llm, connectors=[])\n",
    "# docs = rag.get_relevant_documents(\n",
    "#     user_query,\n",
    "#     documents=compressed_docs,\n",
    "# )\n",
    "# # Print the documents\n",
    "# print(\"Documents:\")\n",
    "# for doc in docs[:-1]:\n",
    "#     print(doc.metadata)\n",
    "#     print(\"\\n\\n\" + doc.page_content)\n",
    "#     print(\"\\n\\n\" + \"-\" * 30 + \"\\n\\n\")\n",
    "# Print the final generation\n",
    "# answer = docs[-1].page_content\n",
    "# print(\"Answer:\")\n",
    "# print(answer)\n",
    "# # Print the final citations\n",
    "# citations = docs[-1].metadata['citations']\n",
    "# print(\"Citations:\")\n",
    "# print(citations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
